html
<html lang="zh_CN">
 <head>
  <meta charset="utf-8"/>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
  <meta content="IE=edge" http-equiv="X-UA-Compatible"/>
  <meta content="width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0,viewport-fit=cover" name="viewport"/>
  <title>
   Mencoba selama beberapa minggu, saya menyimpan 3 model besar di komputer.
  </title>
  <link href="./assets/17462643395990.3286419337108403.css" rel="stylesheet"/>
  <link href="./assets/17462643397560.46681296386005966.css" rel="stylesheet"/>
  <link href="./assets/17462643398860.27100079076025696.css" rel="stylesheet"/>
  <link href="./assets/17462643401840.36730068032591556.css" rel="stylesheet"/>
  <link href="./assets/17462643411760.022284164477721524.css" rel="stylesheet"/>
  <link href="./assets/17462643413150.49509598550083533.css" rel="stylesheet"/>
  <link href="./assets/17462643414550.6029711818966502.css" rel="stylesheet"/>
  <link href="./assets/17462643415980.3282914985472213.css" rel="stylesheet"/>
  <link href="./assets/17462643417370.4859071607692653.css" rel="stylesheet"/>
  <style>
   #page-content,
        #js_article_bottom_bar,
        .__page_content__ {
            max-width: 667px;
            margin: 0 auto;
        }
        img {
            max-width: 100%;
        }
        .sns_opr_btn::before {
            width: 16px;
            height: 16px;
            margin-right: 3px;
        }
  </style>
 </head>
 <body class="zh_CN wx_wap_page wx_wap_desktop_fontsize_2 mm_appmsg comment_feature discuss_tab appmsg_skin_default appmsg_style_default">
  <div class="rich_media" id="js_article" style="position:relative;">
   <div class="rich_media_inner" id="js_base_container">
    <div class="wx_row_immersive_stream_wrap" id="js_row_immersive_stream_wrap">
     <div id="js_row_immersive_cover_img">
      <img alt="cover_image" class="wx_follow_avatar_pic" src="./assets/17462643390500.8684633729664023.jpeg"/>
     </div>
     <div class="wx_row_immersive_stream_mask" id="js_row_immersive_stream_mask">
     </div>
    </div>
    <div class="rich_media_area_primary" id="page-content" style="">
     <div class="rich_media_area_primary_inner">
      <div class="rich_media_wrp" id="img-content">
       <h1 class="rich_media_title" id="activity-name">
        Mencoba selama beberapa minggu, saya menyimpan 3 model besar di komputer.
       </h1>
       <div class="rich_media_meta_list" id="meta_content">
        <span class="wx_tap_link js_wx_tap_highlight rich_media_meta icon_appmsg_tag appmsg_title_tag weui-wa-hotarea" id="copyright_logo">
         Asli
        </span>
        <span class="rich_media_meta rich_media_meta_text">
         Danglive
        </span>
        <span class="rich_media_meta rich_media_meta_nickname" id="profileBt">
         <a class="wx_tap_link js_wx_tap_highlight weui-wa-hotarea" href="javascript:void(0);" id="js_name">
          Danglive
         </a>
         <div id="js_profile_card">
         </div>
        </span>
        <span class="" id="meta_content_hide_info">
         <em class="rich_media_meta rich_media_meta_text" id="publish_time">
          03 Mei 2025 pukul 16.30
         </em>
         <em aria-labelledby="js_a11y_op_ip_wording js_ip_wording" class="rich_media_meta rich_media_meta_text" id="js_ip_wording_wrp" role="option" style="display: inline-block;">
          <span aria-hidden="true" id="js_a11y_op_ip_wording">
          </span>
          <span aria-hidden="true" id="js_ip_wording">
           Shanghai
          </span>
         </em>
         <em aria-labelledby="js_a11y_op_title_modify js_title_modify" class="rich_media_meta rich_media_meta_text" id="js_title_modify_wrp" role="option" style="display: none;">
          <span aria-hidden="true" id="js_title_modify">
          </span>
         </em>
         <span class="wx_tap_link js_wx_tap_highlight rich_media_meta rich_media_meta_link rich_media_meta_star" id="js_star" role="link" style="display: none;" tabindex="0">
         </span>
        </span>
       </div>
       <div class="rich_media_content js_underline_content autoTypeSetting24psection" id="js_content">
        <section>
         <span leaf="">
          Sejak DeepSeek menyediakan kemungkinan untuk mendeploy LLM secara lokal, saya mulai mencoba untuk mendeploy secara lokal menggunakan ollama. Tidak bisa dipungkiri, cara perintah seperti 'ollama run qwen3:14b' sudah sangat sederhana. Ollama langsung mengunduh file model, lalu langsung bisa masuk ke status percakapan.
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          Komputer saya dirakit sendiri pada paruh kedua tahun 2021. Saat itu, harga kartu grafis sedang sangat mahal, jadi awalnya saya menggunakan kartu grafis 1060. Setelah menunggu sebentar, saya menggantinya dengan kartu grafis 3080 Ti 12 GB. Sekarang, tidak perlu lagi mengganti kartu grafis baru hanya untuk menguji LLM, karena kartu grafis dengan memori besar masih tergolong mahal.
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          Beruntungnya para produsen model besar saling bersaing dengan sangat ketat, sehingga model yang tidak penuh darah (non-max) semakin ramah untuk diimplementasikan pada GPU konsumen. Baru-baru ini saya mencoba mengimplementasikan beberapa model secara lokal:
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          qwq:32b-preview-q4_K_M
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          deepseek-r1:32b
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          deepseek-r1:14b
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          gemma3:27b
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          gemma3:12b
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          Qwen3:14B
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          Setelah mencoba, model dengan ukuran 32b berukuran sekitar 20 GB, sehingga sangat memberatkan untuk digunakan di kartu grafis dengan kapasitas 12 GB. Memori video menjadi penuh, dan kecepatan output token terlalu lambat.
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          Jadi, parameter 12b dan 14b ini tetap dipertahankan, ukuran file model dengan skala parameter ini biasanya sekitar 9 GB. Masing-masing adalah:
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          deepseek-r1:14b   9,0GB
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          gemma3:12b         8,1GB
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          Qwen3:14B            9,3GB
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="100000017" data-ratio="0.6138888888888889" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/QX8497U9PKzj1LUsm2Uw0ur5kQEatxyVDkSSdECr5HgHTVoEazAVobU2R6dGiahcqh6zhVVJ3DWHPJaFAaKdlGQ/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1080" src="./assets/17462643392080.2901477842588346.png" type="block"/>
         </span>
        </section>
        <section>
         <span leaf="">
          Dari segi kecepatan eksekusi, yang paling cepat adalah qwen3:14b, dengan tingkat utilisasi GPU yang jauh lebih unggul, dapat mencapai lebih dari 90%. Selain itu, ini adalah model yang menggabungkan inferensi dan non-inferensi, memiliki keunikan tersendiri. Ketika tidak perlu melakukan inferensi, cukup tambahkan "/no_think" dalam percakapan, sehingga respons menjadi lebih langsung dan efisien. Saat memanggil API, meskipun ia masih akan menghasilkan sepasang tag kosong "infer", diperlukan sedikit pemrosesan pada string yang dikembalikan, tetapi jawabannya sudah cukup mudah untuk diproses selanjutnya.
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          gemma3:12b, saya juga masih menyimpannya karena ini adalah model multimodal yang dapat menjelaskan gambar. Namun, saat memanggil API, sedikit merepotkan karena selalu menambahkan penjelasan dan kesimpulan di dalam jawaban. Untuk pemanggilan program yang hanya membutuhkan hasil (misalnya menerjemahkan kalimat pendek), masih perlu menambahkan beberapa instruksi dan pembatasan di dalam prompt.
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          deepseek-r1:14b juga tetap dipertahankan. Karena saya akan memanggil API deepseek di cloud sebagai referensi lokal, utamanya agar bisa sering melihat perbedaan antara versi online dan offline. Ini mungkin model yang paling banyak omong, tapi toh tetap merupakan kebanggaan Tiongkok, jadi menyimpannya adalah sebuah perasaan. Setelah r2 keluar, kemungkinan besar akan diganti dengan salah satu versi dari r2.
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          Konfigurasi komputer sebagai berikut:
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="100000018" data-ratio="0.24722222222222223" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/QX8497U9PKzj1LUsm2Uw0ur5kQEatxyVFVfHnlhdibhV4N5ljSStfIzSfnd1rtI3g6uqgCTq3egWfFYiaqKbpicaQ/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1080" src="./assets/17462643393380.8579404725261033.png" type="block"/>
         </span>
        </section>
        <section>
         <span leaf="">
          Prosesor	AMD Ryzen 9 5950X 16-Core Processor        3.40 GHz
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          RAM onboard 128 GB    2400MHz
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          Versi	Windows 11 Professional
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          Nomor Versi	24H2
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          Kartu Grafis        NVIDIA GeForce RTX 3080 Ti  12GB
         </span>
        </section>
        <p style="display: none;">
         <mp-style-type data-value="3">
         </mp-style-type>
        </p>
       </div>
      </div>
      <div class="rich_media_tool_area" id="js_temp_bottom_area">
       <div class="rich_media_tool__wrp">
        <div class="rich_media_tool">
         <div class="rich_media_info weui-flex">
         </div>
        </div>
       </div>
      </div>
     </div>
    </div>
    <div class="rich_media_area_primary sougou" id="sg_tj" style="display:none">
    </div>
    <div class="rich_media_area_extra">
     <div class="rich_media_area_extra_inner">
      <div id="page_bottom_area">
      </div>
     </div>
    </div>
   </div>
  </div>
  <div class="bottom_bar_wrp" id="js_article_bottom_bar">
   <div id="article_bottom_bar_area">
   </div>
  </div>
  Data komentar
 </body>
</html>

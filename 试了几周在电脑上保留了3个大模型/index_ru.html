html
<html lang="zh_CN">
 <head>
  <meta charset="utf-8"/>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
  <meta content="IE=edge" http-equiv="X-UA-Compatible"/>
  <meta content="width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0,viewport-fit=cover" name="viewport"/>
  <title>
   Попробовал несколько недель, сохранил три крупных модели на компьютере
  </title>
  <link href="./assets/17462643395990.3286419337108403.css" rel="stylesheet"/>
  <link href="./assets/17462643397560.46681296386005966.css" rel="stylesheet"/>
  <link href="./assets/17462643398860.27100079076025696.css" rel="stylesheet"/>
  <link href="./assets/17462643401840.36730068032591556.css" rel="stylesheet"/>
  <link href="./assets/17462643411760.022284164477721524.css" rel="stylesheet"/>
  <link href="./assets/17462643413150.49509598550083533.css" rel="stylesheet"/>
  <link href="./assets/17462643414550.6029711818966502.css" rel="stylesheet"/>
  <link href="./assets/17462643415980.3282914985472213.css" rel="stylesheet"/>
  <link href="./assets/17462643417370.4859071607692653.css" rel="stylesheet"/>
  <style>
   #page-content,
        #js_article_bottom_bar,
        .__page_content__ {
            max-width: 667px;
            margin: 0 auto;
        }
        img {
            max-width: 100%;
        }
        .sns_opr_btn::before {
            width: 16px;
            height: 16px;
            margin-right: 3px;
        }
  </style>
 </head>
 <body class="zh_CN wx_wap_page wx_wap_desktop_fontsize_2 mm_appmsg comment_feature discuss_tab appmsg_skin_default appmsg_style_default">
  <div class="rich_media" id="js_article" style="position:relative;">
   <div class="rich_media_inner" id="js_base_container">
    <div class="wx_row_immersive_stream_wrap" id="js_row_immersive_stream_wrap">
     <div id="js_row_immersive_cover_img">
      <img alt="cover_image" class="wx_follow_avatar_pic" src="./assets/17462643390500.8684633729664023.jpeg"/>
     </div>
     <div class="wx_row_immersive_stream_mask" id="js_row_immersive_stream_mask">
     </div>
    </div>
    <div class="rich_media_area_primary" id="page-content" style="">
     <div class="rich_media_area_primary_inner">
      <div class="rich_media_wrp" id="img-content">
       <h1 class="rich_media_title" id="activity-name">
        Попробовал несколько недель, сохранил три крупных модели на компьютере
       </h1>
       <div class="rich_media_meta_list" id="meta_content">
        <span class="wx_tap_link js_wx_tap_highlight rich_media_meta icon_appmsg_tag appmsg_title_tag weui-wa-hotarea" id="copyright_logo">
         Оригинал
        </span>
        <span class="rich_media_meta rich_media_meta_text">
         Данглаиве
        </span>
        <span class="rich_media_meta rich_media_meta_nickname" id="profileBt">
         <a class="wx_tap_link js_wx_tap_highlight weui-wa-hotarea" href="javascript:void(0);" id="js_name">
          Данглаивэ
         </a>
         <div id="js_profile_card">
         </div>
        </span>
        <span class="" id="meta_content_hide_info">
         <em class="rich_media_meta rich_media_meta_text" id="publish_time">
          03 мая 2025 года, 16:30
         </em>
         <em aria-labelledby="js_a11y_op_ip_wording js_ip_wording" class="rich_media_meta rich_media_meta_text" id="js_ip_wording_wrp" role="option" style="display: inline-block;">
          <span aria-hidden="true" id="js_a11y_op_ip_wording">
          </span>
          <span aria-hidden="true" id="js_ip_wording">
           Шанхай
          </span>
         </em>
         <em aria-labelledby="js_a11y_op_title_modify js_title_modify" class="rich_media_meta rich_media_meta_text" id="js_title_modify_wrp" role="option" style="display: none;">
          <span aria-hidden="true" id="js_title_modify">
          </span>
         </em>
         <span class="wx_tap_link js_wx_tap_highlight rich_media_meta rich_media_meta_link rich_media_meta_star" id="js_star" role="link" style="display: none;" tabindex="0">
         </span>
        </span>
       </div>
       <div class="rich_media_content js_underline_content autoTypeSetting24psection" id="js_content">
        <section>
         <span leaf="">
          После того как DeepSeek предоставил возможность локального развертывания LLM, я начал пробовать использовать Ollama для локального развертывания. Нельзя не сказать, что команда вроде «ollama run qwen3:14b» уже настолько проста. Ollama напрямую загружает файлы модели, а затем сразу переходит в режим диалога.
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          Мой компьютер я собрал сам во второй половине 2021 года. В то время видеокарты были особенно дорогими, поэтому сначала я использовал видеокарту 1060, а позже, подождав некоторое время, заменил её на 3080 Ti с 12 ГБ видеопамяти. Теперь нет необходимости менять видеокарту на новую для тестирования LLM, разумеется, видеокарты с большой видеопамятью всё ещё довольно дорогие.
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          К счастью, крупные производители моделей активно конкурируют друг с другом, и модели, не имеющие полной мощности, становятся всё более удобными для развертывания на потребительских видеокартах. Недавно я в основном тестировал несколько моделей, развернутых локально:
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          qwq:32b-preview-q4_K_M
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          DeepSeek-R1:32B
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          DeepSeek-R1:14B
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          gemma3:27b
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          gemma3:12b
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          Qwen3:14B
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          Попробовав, модель размером 32b, сама по себе около 20 ГБ, очень тяжело работает на видеокарте объемом 12 ГБ, полностью заполняя видеопамять, и скорость генерации токенов слишком медленная.
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          Поэтому модели с параметрами 12b и 14b, такого масштаба параметров, обычно имеют размер файла около 9 ГБ. Они следующие:
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          deepseek-r1:14b   9,0 ГБ
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          gemma3:12b         8,1 ГБ
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          Qwen3:14B            9,3 ГБ
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="100000017" data-ratio="0.6138888888888889" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/QX8497U9PKzj1LUsm2Uw0ur5kQEatxyVDkSSdECr5HgHTVoEazAVobU2R6dGiahcqh6zhVVJ3DWHPJaFAaKdlGQ/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1080" src="./assets/17462643392080.2901477842588346.png" type="block"/>
         </span>
        </section>
        <section>
         <span leaf="">
          С точки зрения скорости выполнения, самым быстрым является qwen3:14b, поскольку использование GPU превосходит другие модели и может достигать более 90%. Кроме того, это модель, объединяющая функции вывода и невывода, что делает её уникальной. Когда вывод не требуется, достаточно добавить в диалог "/no_think", и ответы станут более прямыми и краткими. При вызове через API, хотя она всё ещё выводит пару пустых тегов &lt;thinking&gt;, потребуется обработать возвращаемую строку, но её ответы уже достаточно просты для дальнейшей обработки.
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          gemma3:12b, я также сохранил её, потому что это многофункциональная модель, которая может интерпретировать изображения. Однако, при вызове через API, немного надоедает, что она постоянно добавляет в ответы вступительные фразы и итоговые выводы. Для программных вызовов, где требуется только результат (например, перевод небольшого текста), в prompt необходимо добавлять некоторые указания и ограничения.
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          DeepSeek-R1:14B также сохранили. Потому что я использую API DeepSeek в облаке как локальную точку сравнения, чтобы периодически смотреть различия между онлайн и оффлайн версиями. Это, наверное, самый болтливый модель, но всё же это гордость Китая, поэтому оставили из-за эмоциональной привязанности. Когда выйдет R2, вероятно, его заменят на какую-то версию R2.
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          Конфигурация компьютера следующая:
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="100000018" data-ratio="0.24722222222222223" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/QX8497U9PKzj1LUsm2Uw0ur5kQEatxyVFVfHnlhdibhV4N5ljSStfIzSfnd1rtI3g6uqgCTq3egWfFYiaqKbpicaQ/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1080" src="./assets/17462643393380.8579404725261033.png" type="block"/>
         </span>
        </section>
        <section>
         <span leaf="">
          Процессор	AMD Ryzen 9 5950X 16-ядерный процессор	3,40 ГГц
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          Оперативная память, установленная на материнскую плату: 128 ГБ, 2400 МГц
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          Версия	Windows 11 Профессиональная
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          Номер версии	24H2
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          Видеокарта NVIDIA GeForce RTX 3080 Ti 12 ГБ
         </span>
        </section>
        <p style="display: none;">
         <mp-style-type data-value="3">
         </mp-style-type>
        </p>
       </div>
      </div>
      <div class="rich_media_tool_area" id="js_temp_bottom_area">
       <div class="rich_media_tool__wrp">
        <div class="rich_media_tool">
         <div class="rich_media_info weui-flex">
         </div>
        </div>
       </div>
      </div>
     </div>
    </div>
    <div class="rich_media_area_primary sougou" id="sg_tj" style="display:none">
    </div>
    <div class="rich_media_area_extra">
     <div class="rich_media_area_extra_inner">
      <div id="page_bottom_area">
      </div>
     </div>
    </div>
   </div>
  </div>
  <div class="bottom_bar_wrp" id="js_article_bottom_bar">
   <div id="article_bottom_bar_area">
   </div>
  </div>
  Данные комментариев
 </body>
</html>

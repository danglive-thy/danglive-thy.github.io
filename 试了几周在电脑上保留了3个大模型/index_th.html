ภาษา html
<html lang="zh_CN">
 <head>
  <meta charset="utf-8"/>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
  <meta content="IE=edge" http-equiv="X-UA-Compatible"/>
  <meta content="width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0,viewport-fit=cover" name="viewport"/>
  <title>
   ลองใช้มาหลายสัปดาห์ แล้วก็เก็บโมเดลใหญ่ 3 ตัวไว้บนคอมพิวเตอร์
  </title>
  <link href="./assets/17462643395990.3286419337108403.css" rel="stylesheet"/>
  <link href="./assets/17462643397560.46681296386005966.css" rel="stylesheet"/>
  <link href="./assets/17462643398860.27100079076025696.css" rel="stylesheet"/>
  <link href="./assets/17462643401840.36730068032591556.css" rel="stylesheet"/>
  <link href="./assets/17462643411760.022284164477721524.css" rel="stylesheet"/>
  <link href="./assets/17462643413150.49509598550083533.css" rel="stylesheet"/>
  <link href="./assets/17462643414550.6029711818966502.css" rel="stylesheet"/>
  <link href="./assets/17462643415980.3282914985472213.css" rel="stylesheet"/>
  <link href="./assets/17462643417370.4859071607692653.css" rel="stylesheet"/>
  <style>
   #page-content,
        #js_article_bottom_bar,
        .__page_content__ {
            max-width: 667px;
            margin: 0 auto;
        }
        img {
            max-width: 100%;
        }
        .sns_opr_btn::before {
            width: 16px;
            height: 16px;
            margin-right: 3px;
        }
  </style>
 </head>
 <body class="zh_CN wx_wap_page wx_wap_desktop_fontsize_2 mm_appmsg comment_feature discuss_tab appmsg_skin_default appmsg_style_default">
  <div class="rich_media" id="js_article" style="position:relative;">
   <div class="rich_media_inner" id="js_base_container">
    <div class="wx_row_immersive_stream_wrap" id="js_row_immersive_stream_wrap">
     <div id="js_row_immersive_cover_img">
      <img alt="cover_image" class="wx_follow_avatar_pic" src="./assets/17462643390500.8684633729664023.jpeg"/>
     </div>
     <div class="wx_row_immersive_stream_mask" id="js_row_immersive_stream_mask">
     </div>
    </div>
    <div class="rich_media_area_primary" id="page-content" style="">
     <div class="rich_media_area_primary_inner">
      <div class="rich_media_wrp" id="img-content">
       <h1 class="rich_media_title" id="activity-name">
        ลองใช้งานมาหลายสัปดาห์แล้ว ตอนนี้มีโมเดลขนาดใหญ่ 3 โมเดลที่เก็บไว้บนคอมพิวเตอร์
       </h1>
       <div class="rich_media_meta_list" id="meta_content">
        <span class="wx_tap_link js_wx_tap_highlight rich_media_meta icon_appmsg_tag appmsg_title_tag weui-wa-hotarea" id="copyright_logo">
         ต้นฉบับ
        </span>
        <span class="rich_media_meta rich_media_meta_text">
         ดังไลฟ์
        </span>
        <span class="rich_media_meta rich_media_meta_nickname" id="profileBt">
         <a class="wx_tap_link js_wx_tap_highlight weui-wa-hotarea" href="javascript:void(0);" id="js_name">
          ดังไลฟ์
         </a>
         <div id="js_profile_card">
         </div>
        </span>
        <span class="" id="meta_content_hide_info">
         <em class="rich_media_meta rich_media_meta_text" id="publish_time">
          วันที่ 3 พฤษภาคม 2568 เวลา 16.30 น.
         </em>
         <em aria-labelledby="js_a11y_op_ip_wording js_ip_wording" class="rich_media_meta rich_media_meta_text" id="js_ip_wording_wrp" role="option" style="display: inline-block;">
          <span aria-hidden="true" id="js_a11y_op_ip_wording">
          </span>
          <span aria-hidden="true" id="js_ip_wording">
           เซี่ยงไฮ้
          </span>
         </em>
         <em aria-labelledby="js_a11y_op_title_modify js_title_modify" class="rich_media_meta rich_media_meta_text" id="js_title_modify_wrp" role="option" style="display: none;">
          <span aria-hidden="true" id="js_title_modify">
          </span>
         </em>
         <span class="wx_tap_link js_wx_tap_highlight rich_media_meta rich_media_meta_link rich_media_meta_star" id="js_star" role="link" style="display: none;" tabindex="0">
         </span>
        </span>
       </div>
       <div class="rich_media_content js_underline_content autoTypeSetting24psection" id="js_content">
        <section>
         <span leaf="">
          ตั้งแต่ deepseek นำเสนอความเป็นไปได้ในการติดตั้ง LLM ที่สถานที่ตั้งแล้ว ก็เริ่มลองใช้ ollama เพื่อติดตั้งที่สถานที่ตั้ง ต้องยอมรับว่า คำสั่งเช่น ollama run qwen3:14b นั้นง่ายมาก หลังจากที่ ollama ดาวน์โหลดไฟล์โมเดลแล้ว ก็สามารถเข้าสู่สถานะการสนทนาได้ทันที
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          คอมพิวเตอร์ของฉันเป็นของประกอบเองช่วงครึ่งหลังปี 2021 ตอนนั้นอยู่ในช่วงที่การ์ดจอราคาสูงมาก จึงใช้การ์ดจอรุ่น 1060 ก่อน ต่อมาหลังจากรอช่วงหนึ่ง ก็เปลี่ยนเป็นการ์ดจอรุ่น 3080Ti 12GB ปัจจุบันยังไม่จำเป็นต้องเปลี่ยนการ์ดจอใหม่เพื่อทดสอบ LLM เพราะการ์ดจอที่มีหน่วยความจำขนาดใหญ่ยังคงมีราคาค่อนข้างสูงอยู่ดี
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          โชคดีที่ผู้ผลิตโมเดลขนาดใหญ่ต่างกันแข่งกันอย่างรุนแรง ทำให้โมเดลที่ไม่ใช่แบบ Full-Blood นั้นเริ่มมีความเป็นมิตรมากขึ้นในการติดตั้งบน GPU สำหรับผู้บริโภค ช่วงนี้ทดลองติดตั้งโมเดลที่ใช้ในท้องถิ่นหลายตัว:
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          ควอว์:32b-พรีวิว-q4_K_M
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          DeepSeek-R1:32B
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          DeepSeek-R1:14B
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          เจมมา3:27บ
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          เจมมา 3:12บี
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          Qwen3:14b
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          เมื่อทดสอบดู โมเดลขนาด 32b ซึ่งมีขนาดประมาณ 20 GB นั้นใช้การ์ดจอที่มีขนาด 12 GB แล้วรู้สึกหนักมาก ใช้หน่วยความจำทั้งหมดและยังมีความเร็วในการสร้าง token ที่ช้ามากอีกด้วย
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          ดังนั้น โมเดลที่มีขนาดพารามิเตอร์ 12b และ 14b นี้ ซึ่งอยู่ในระดับขนาดพารามิเตอร์ดังกล่าว ไฟล์ของโมเดลนี้มักมีขนาดประมาณ 9GB โดยมีดังนี้:
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          DeepSeek-R1:14B   9.0GB
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          เจมมา 3:12บี         8.1 จีบี
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          Qwen3:14B            9.3 GB
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="100000017" data-ratio="0.6138888888888889" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/QX8497U9PKzj1LUsm2Uw0ur5kQEatxyVDkSSdECr5HgHTVoEazAVobU2R6dGiahcqh6zhVVJ3DWHPJaFAaKdlGQ/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1080" src="./assets/17462643392080.2901477842588346.png" type="block"/>
         </span>
        </section>
        <section>
         <span leaf="">
          จากมุมมองความเร็วในการทำงาน โมเดลที่เร็วที่สุดคือ Qwen3:14B ซึ่งมีอัตราการใช้งาน GPU สูงมาก สามารถไปถึงมากกว่า 90% ด้วยกัน นอกจากนี้ยังเป็นโมเดลที่รวมทั้งการสืบค้นและไม่สืบค้นไว้ด้วยกัน จึงมีความพิเศษ เมื่อไม่ต้องการใช้การสืบค้น เพียงแค่เพิ่มคำว่า "/no_think" ไว้ในบทสนทนา ก็จะทำให้คำตอบมีความกระชับมากขึ้น ในการเรียกใช้งานผ่าน API แม้ว่ามันจะยังคงส่งคู่ของแท็ก &lt;span class="nothink"&gt; ที่ว่างเปล่าออกมา ซึ่งต้องมีการประมวลผลเพิ่มเติมในสตริงที่คืนค่ากลับมา แต่คำตอบของมันก็ถือว่าเป็นไปได้ที่จะประมวลผลต่อได้ง่ายพอสมควรแล้ว
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          Gemma3:12B ฉันก็ยังคงใช้อยู่ด้วย เพราะเป็นโมเดลที่หลายรูปแบบ สามารถอธิบายภาพได้ แต่ก็มีปัญหาเล็กน้อยตอนเรียกใช้ API มันมักจะใส่คำอธิบายและสรุปผลในคำตอบเสมอ ซึ่งสำหรับการเรียกใช้ที่ต้องการแค่ผลลัพธ์เท่านั้น (เช่น การแปลประโยคสั้นๆ) จะต้องเพิ่มคำสั่งและข้อจำกัดใน prompt เพื่อให้ได้ผลลัพธ์ที่ต้องการมากขึ้น
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          DeepSeek-R1:14B ยังถูกเก็บไว้ด้วย เพราะผมจะเรียกใช้ API ของ DeepSeek บนคลาวด์ เพื่อเป็นข้อมูลอ้างอิงในท้องถิ่น หลัก ๆ ก็เพื่อที่จะสามารถเปรียบเทียบความแตกต่างระหว่างเวอร์ชันออนไลน์และออฟไลน์ได้บ้าง มัน大概是模型中最啰嗦的一个了 แต่ก็เป็นความภาคภูมิใจของจีน จึงยังคงไว้ด้วยความรู้สึกบางอย่าง พอถึงเวลาที่ R2 ออกมา คาดว่ามันจะถูกแทนที่ด้วยเวอร์ชันหนึ่งของ R2
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          การตั้งค่าคอมพิวเตอร์ดังนี้:
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          <img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="100000018" data-ratio="0.24722222222222223" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/QX8497U9PKzj1LUsm2Uw0ur5kQEatxyVFVfHnlhdibhV4N5ljSStfIzSfnd1rtI3g6uqgCTq3egWfFYiaqKbpicaQ/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1080" src="./assets/17462643393380.8579404725261033.png" type="block"/>
         </span>
        </section>
        <section>
         <span leaf="">
          หน่วยประมวลผล   ซีพียู AMD Ryzen 9 5950X 16-Core Processor        ความถี่ 3.40 GHz
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          RAM ที่ติดมาพร้อมเครื่อง 128 GB    2400MHz
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          เวอร์ชัน	Windows 11 โปรเฟสชันนัล
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          หมายเลขเวอร์ชัน	24H2
         </span>
         <span leaf="">
          <br/>
         </span>
         <span leaf="">
          การ์ดจอ NVIDIA GeForce RTX 3080 Ti 12GB
         </span>
        </section>
        <p style="display: none;">
         <mp-style-type data-value="3">
         </mp-style-type>
        </p>
       </div>
      </div>
      <div class="rich_media_tool_area" id="js_temp_bottom_area">
       <div class="rich_media_tool__wrp">
        <div class="rich_media_tool">
         <div class="rich_media_info weui-flex">
         </div>
        </div>
       </div>
      </div>
     </div>
    </div>
    <div class="rich_media_area_primary sougou" id="sg_tj" style="display:none">
    </div>
    <div class="rich_media_area_extra">
     <div class="rich_media_area_extra_inner">
      <div id="page_bottom_area">
      </div>
     </div>
    </div>
   </div>
  </div>
  <div class="bottom_bar_wrp" id="js_article_bottom_bar">
   <div id="article_bottom_bar_area">
   </div>
  </div>
  ข้อมูลความคิดเห็น
 </body>
</html>
